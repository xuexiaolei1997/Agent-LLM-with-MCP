{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools, Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexi\\AppData\\Local\\Temp\\ipykernel_12772\\474422626.py:2: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  ollama_llm = ChatOllama(model=\"deepseek-r1:8b\")\n"
     ]
    }
   ],
   "source": [
    "# 初始化大模型\n",
    "ollama_llm = ChatOllama(model=\"deepseek-r1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexi\\AppData\\Local\\Temp\\ipykernel_12772\\1492916406.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  intent_chain = LLMChain(llm=ollama_llm, prompt=intent_prompt)\n"
     ]
    }
   ],
   "source": [
    "# 意图提取\n",
    "intent_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"从以下文本中提取意图：{input}\",\n",
    ")\n",
    "intent_chain = LLMChain(llm=ollama_llm, prompt=intent_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规划\n",
    "plan_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"根据以下文本生成一个计划：{input}\",\n",
    ")\n",
    "plan_chain = LLMChain(llm=ollama_llm, prompt=plan_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexi\\AppData\\Local\\Temp\\ipykernel_12772\\1595264515.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# 记忆体\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "# 工具\n",
    "def run_cmd(command: str) -> str:\n",
    "        \"\"\"运行本地CMD命令\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "            return result.stdout\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"run_command\",\n",
    "        func=run_cmd,\n",
    "        description=\"用于运行本地CMD命令\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexi\\AppData\\Local\\Temp\\ipykernel_12772\\82190615.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# 智能体\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    ollama_llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户意图: <think>\n",
      "嗯，用户发来一个请求，让我提取他们提供的文本中的意图。文本是：“请打开本地的浏览器，我是windows，你直接打开就可以了”。首先，我需要分析这句话的结构和内容。\n",
      "\n",
      "看起来用户是在指导某人如何操作，比如在某个环境下启动浏览器。他们提到“我是windows”，可能指的是操作系统是Windows，所以需要使用适用于Windows的方法来打开浏览器。此外，用户用了“直接打开就可以了”这句话，这可能意味着步骤比较简单，只需执行一个动作。\n",
      "\n",
      "接下来，我要考虑用户的意图。他们可能是在指导另一个人如何在本地环境下启动浏览器，而没有进一步的技术细节或复杂步骤。因此，提取的意图应该是关于打开本地浏览器，并且操作系统是Windows。\n",
      "\n",
      "也许用户是在设置某个应用程序或者配置环境，只需要浏览器就可以完成。这可能涉及到开发、配置或测试过程中的一个步骤。不过，由于信息有限，我只能基于提供的文本进行分析。\n",
      "\n",
      "总结一下，用户的意图应该是启动本地的浏览器，并且是在Windows操作系统环境下进行。所以提取的关键词应该是“打开本地浏览器”和“windows”。\n",
      "</think>\n",
      "\n",
      "从文本中提取的意图是：**请在本地环境下打开浏览器，操作系统为Windows**。\n",
      "执行计划: <think>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<think>\n",
      "嗯，用户让我“请打开本地的浏览器”，而且他是Windows用户。我需要先确认他的操作系统，然后决定如何启动浏览器。既然用户已经说了是Windows，那我就不用再询问了。\n",
      "\n",
      "接下来，我应该使用哪种命令来启动浏览器呢？通常在Windows上，Chrome和Firefox都是常用的。但默认情况下，可能会选择Chrome，所以直接运行start chrome.exe比较合适。不过，也许用户有自己的偏好，这时候是否需要进一步确认呢？\n",
      "\n",
      "根据之前的对话历史，我已经询问过用户是否需要帮助选择浏览器，但这次用户没有提到具体的偏好，只是简单地重复了同样的请求。所以我觉得直接运行start chrome.exe足够了，不用再多余的问题了。\n",
      "\n",
      "然后，我需要执行这个命令，看看结果如何。如果有错误，比如启动失败，可能需要调整参数或者换成其他浏览器。但目前来看，没有问题，所以不需要进一步的工具使用。\n",
      "\n",
      "总结一下，用户是Windows用户，直接启动Chrome即可，无需额外确认。所以，我的回应应该简短明了，完成任务即可。\n",
      "</think>\n",
      "\n",
      "Thought: 是否需要使用工具? 是  \n",
      "Action: run_command  \n",
      "Action Input: start chrome.exe\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "AI: 我已经运行了命令start chrome.exe来启动你的本地浏览器。如果你有其他偏好或遇到问题，可以告诉我，我会帮助你调整。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "我已经运行了命令start chrome.exe来启动你的本地浏览器。如果你有其他偏好或遇到问题，可以告诉我，我会帮助你调整。\n"
     ]
    }
   ],
   "source": [
    "query = \"请打开本地的浏览器，我是windows，你直接打开就可以了\"\n",
    "#提取意图\n",
    "intent = intent_chain.run(query)\n",
    "print(f\"用户意图: {intent}\")\n",
    "#规划\n",
    "plan = plan_chain.run(intent)\n",
    "print(f\"执行计划: {plan}\")\n",
    "#agent 执行\n",
    "response = agent.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
